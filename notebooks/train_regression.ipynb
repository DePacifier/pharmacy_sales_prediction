{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Regression Models using sklearn pipelines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Without Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#importing Libraries\r\n",
    "import pandas as pd\r\n",
    "# import dvc.api\r\n",
    "import os\r\n",
    "import sys\r\n",
    "import numpy as np\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "import mlflow\r\n",
    "#import local libraries\r\n",
    "#Adding scripts path\r\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\r\n",
    "from scripts.data_loader import load_df_from_csv\r\n",
    "from scripts.ML_modelling_utils import *\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Clean Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "clean_data = load_df_from_csv('../data/train.csv')\r\n",
    "y_values = clean_data['Sales']\r\n",
    "x_values = clean_data.drop(['Sales'],axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training using Random Forest Regressor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Splitting Data (60,20,20)\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size=0.2, random_state=42)\r\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "mlflow.autolog(log_input_examples=True, log_model_signatures=True, log_models=False, silent=True)\r\n",
    "# Create a based model\r\n",
    "rf = RandomForestRegressor()\r\n",
    "with mlflow.start_run() as run:\r\n",
    "    rf.fit(x_train, y_train)\r\n",
    "\r\n",
    "    train_score = rf.score(x_train, y_train)\r\n",
    "    valid_score = rf.score(x_valid,y_valid)\r\n",
    "    valid_metrics = calculate_metrics(y_valid,rf.predict(x_valid),\"Validation \")\r\n",
    "    test_score = rf.score(x_test,y_test)\r\n",
    "    test_metrics = calculate_metrics(y_test, rf.predict(x_test), \"Test \")\r\n",
    "\r\n",
    "    mlflow.log_metric(\"Valid Score\", valid_score)\r\n",
    "    mlflow.log_metrics(valid_metrics)\r\n",
    "    mlflow.log_metric(\"Test Score\", test_score)\r\n",
    "    mlflow.log_metrics(test_metrics)\r\n",
    "    mlflow.sklearn.log_model(rf, generate_model_name(test_metrics['Test RMSE Score']))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Modelling Utilities:INFO->RMSE Score is: 0.23\n",
      "Modelling Utilities:INFO->R2 Square Score is: 0.95\n",
      "Modelling Utilities:INFO->MAE Score is: 0.13\n",
      "Modelling Utilities:INFO->RMSE Score is: 0.23\n",
      "Modelling Utilities:INFO->R2 Square Score is: 0.95\n",
      "Modelling Utilities:INFO->MAE Score is: 0.13\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9918217208283953"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "valid_score"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9464088698187895"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "valid_metrics"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'RMSE Score': 0.23207756030571391,\n",
       " 'R2_Squared': 0.9464088698187895,\n",
       " 'MAE Score': 0.13363749553641205}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "test_metrics\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'RMSE Score': 0.23242887038376997,\n",
       " 'R2_Squared': 0.9458018010617835,\n",
       " 'MAE Score': 0.13350047867580667}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "features = pd.DataFrame()\r\n",
    "features[\"Feature\"] = x_train.columns\r\n",
    "features[\"Importance\"] = rf.feature_importances_\r\n",
    "features.sort_values(by='Importance', ascending=False)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      Feature  Importance\n",
       "7                        Open    0.460141\n",
       "15        CompetitionDistance    0.161633\n",
       "8                       Promo    0.073437\n",
       "17   CompetitionOpenSinceYear    0.050305\n",
       "16  CompetitionOpenSinceMonth    0.049603\n",
       "0                   DayOfWeek    0.033223\n",
       "19            Promo2SinceWeek    0.024841\n",
       "13                  StoreType    0.024464\n",
       "5                         Day    0.022929\n",
       "3                       Month    0.019423\n",
       "20            Promo2SinceYear    0.015941\n",
       "14                 Assortment    0.014996\n",
       "11              DaysToHoliday    0.012684\n",
       "21              PromoInterval    0.008819\n",
       "2                        Year    0.008017\n",
       "10           DaysAfterHoliday    0.004218\n",
       "18                     Promo2    0.003755\n",
       "1                     WeekDay    0.003742\n",
       "12              SchoolHoliday    0.002643\n",
       "4                      Season    0.002442\n",
       "6                 MonthTiming    0.001902\n",
       "9                StateHoliday    0.000842"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Open</td>\n",
       "      <td>0.460141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CompetitionDistance</td>\n",
       "      <td>0.161633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Promo</td>\n",
       "      <td>0.073437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CompetitionOpenSinceYear</td>\n",
       "      <td>0.050305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CompetitionOpenSinceMonth</td>\n",
       "      <td>0.049603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DayOfWeek</td>\n",
       "      <td>0.033223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Promo2SinceWeek</td>\n",
       "      <td>0.024841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>StoreType</td>\n",
       "      <td>0.024464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Day</td>\n",
       "      <td>0.022929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Month</td>\n",
       "      <td>0.019423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Promo2SinceYear</td>\n",
       "      <td>0.015941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Assortment</td>\n",
       "      <td>0.014996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DaysToHoliday</td>\n",
       "      <td>0.012684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PromoInterval</td>\n",
       "      <td>0.008819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.008017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DaysAfterHoliday</td>\n",
       "      <td>0.004218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Promo2</td>\n",
       "      <td>0.003755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeekDay</td>\n",
       "      <td>0.003742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SchoolHoliday</td>\n",
       "      <td>0.002643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Season</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MonthTiming</td>\n",
       "      <td>0.001902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StateHoliday</td>\n",
       "      <td>0.000842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameter Tunning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create the parameter grid based on the results of random search\r\n",
    "param_grid = {\r\n",
    "    'bootstrap': [True],\r\n",
    "    'criterion': ['mse'],\r\n",
    "    'max_depth': [10, 15, 20],\r\n",
    "    'max_features': [2, 3],\r\n",
    "    'n_estimators': [10, 15],\r\n",
    "    'warm_start': [True]\r\n",
    "}\r\n",
    "\r\n",
    "rf2 = RandomForestRegressor()\r\n",
    "# Instantiate the grid search model\r\n",
    "grid_search = GridSearchCV(estimator=rf2, param_grid=param_grid,\r\n",
    "                           cv=3, n_jobs=-1, verbose=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**MSE** is used to check how close estimates or forecasts are to actual values. Lower the MSE, the closer is forecast to actual."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Fit the grid search to the data\r\n",
    "mlflow.autolog(log_input_examples=True, log_model_signatures=True, log_models=False, silent=True)\r\n",
    "with mlflow.start_run() as run:\r\n",
    "    best_model = grid_search.fit(x_train, y_train)\r\n",
    "\r\n",
    "    train_score = best_model.score(x_train,y_train)\r\n",
    "    valid_score = best_model.score(x_valid, y_valid)\r\n",
    "    valid_metrics = calculate_metrics(\r\n",
    "        y_valid, best_model.predict(x_valid), \"Validation \")\r\n",
    "    test_score = best_model.score(x_test, y_test)\r\n",
    "    test_metrics = calculate_metrics(\r\n",
    "        y_test, best_model.predict(x_test), \"Test \")\r\n",
    "\r\n",
    "    mlflow.log_metric(\"Valid Score\", valid_score)\r\n",
    "    mlflow.log_metrics(valid_metrics)\r\n",
    "    mlflow.log_metric(\"Test Score\", test_score)\r\n",
    "    mlflow.log_metrics(test_metrics)\r\n",
    "    mlflow.sklearn.log_model(best_model, generate_model_name(\r\n",
    "        test_metrics['Test RMSE Score']))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Modelling Utilities:INFO->RMSE Score is: 45.95221%\n",
      "Modelling Utilities:INFO->R2 Square Score is: 78.98935%\n",
      "Modelling Utilities:INFO->MAE Score is: 29.64358%\n",
      "Modelling Utilities:INFO->RMSE Score is: 45.58945%\n",
      "Modelling Utilities:INFO->R2 Square Score is: 79.14868%\n",
      "Modelling Utilities:INFO->MAE Score is: 29.50637%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "best_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': 20,\n",
       " 'max_features': 3,\n",
       " 'n_estimators': 10,\n",
       " 'warm_start': True}"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "grid_features = pd.DataFrame()\r\n",
    "grid_features[\"Feature\"] = x_train.columns\r\n",
    "grid_features[\"Importance\"] = best_model.best_estimator_.feature_importances_\r\n",
    "grid_features.sort_values(by='Importance', ascending=False)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      Feature  Importance\n",
       "7                        Open    0.235976\n",
       "0                   DayOfWeek    0.221043\n",
       "8                       Promo    0.123794\n",
       "15        CompetitionDistance    0.080959\n",
       "1                     WeekDay    0.051712\n",
       "9                StateHoliday    0.037606\n",
       "16  CompetitionOpenSinceMonth    0.036478\n",
       "17   CompetitionOpenSinceYear    0.035154\n",
       "5                         Day    0.025608\n",
       "13                  StoreType    0.022285\n",
       "19            Promo2SinceWeek    0.020090\n",
       "3                       Month    0.019161\n",
       "14                 Assortment    0.018355\n",
       "20            Promo2SinceYear    0.017477\n",
       "11              DaysToHoliday    0.014217\n",
       "10           DaysAfterHoliday    0.007415\n",
       "21              PromoInterval    0.007240\n",
       "2                        Year    0.006389\n",
       "18                     Promo2    0.005649\n",
       "4                      Season    0.005311\n",
       "12              SchoolHoliday    0.004436\n",
       "6                 MonthTiming    0.003644"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Open</td>\n",
       "      <td>0.235976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DayOfWeek</td>\n",
       "      <td>0.221043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Promo</td>\n",
       "      <td>0.123794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CompetitionDistance</td>\n",
       "      <td>0.080959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeekDay</td>\n",
       "      <td>0.051712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>StateHoliday</td>\n",
       "      <td>0.037606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CompetitionOpenSinceMonth</td>\n",
       "      <td>0.036478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CompetitionOpenSinceYear</td>\n",
       "      <td>0.035154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Day</td>\n",
       "      <td>0.025608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>StoreType</td>\n",
       "      <td>0.022285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Promo2SinceWeek</td>\n",
       "      <td>0.020090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Month</td>\n",
       "      <td>0.019161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Assortment</td>\n",
       "      <td>0.018355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Promo2SinceYear</td>\n",
       "      <td>0.017477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DaysToHoliday</td>\n",
       "      <td>0.014217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DaysAfterHoliday</td>\n",
       "      <td>0.007415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PromoInterval</td>\n",
       "      <td>0.007240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Year</td>\n",
       "      <td>0.006389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Promo2</td>\n",
       "      <td>0.005649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Season</td>\n",
       "      <td>0.005311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SchoolHoliday</td>\n",
       "      <td>0.004436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MonthTiming</td>\n",
       "      <td>0.003644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Using Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading just merged unclean data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "merged_data = load_df_from_csv('../data/train.csv')\r\n",
    "y_values = merged_data['Sales']\r\n",
    "x_values = merged_data.drop(['Sales'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spliting Data Sets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# Splitting Data (60,20,20)\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size=0.2, random_state=42)\r\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Transformers for our numeric and categorical data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "class CustomMaxImputer(BaseEstimator, TransformerMixin):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        \r\n",
    "    def fit(self, X, y=0):\r\n",
    "        self.max_value = X.max()\r\n",
    "\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X, y=0):\r\n",
    "        return np.where(X.isna(), self.max_value, X)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "class CustomMostFrequentImputer(BaseEstimator, TransformerMixin):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "    def fit(self, X, y=0):\r\n",
    "        most_occuring = Counter(X.flat).most_common(1)\r\n",
    "        self.mode_value = most_occuring[0][0]\r\n",
    "\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X, y=0):\r\n",
    "        return np.where(X.isna(), self.mode_value, X)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "numeric_transformer = Pipeline(steps=[\r\n",
    "    ('custom_max', CustomMaxImputer()),\r\n",
    "    ('scaler', StandardScaler())\r\n",
    "])\r\n",
    "categorical_transformer = Pipeline(steps=[\r\n",
    "    ('custom_mode', SimpleImputer(strategy='most_frequent')),\r\n",
    "    ('encoder', OneHotEncoder()),\r\n",
    "])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Identifying our columns and passing it to a ColumnTransformer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Scaling Sales column\r\n",
    "merged_data['Sales'] = numeric_transformer.fit_transform(merged_data[[\"Sales\"]])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "numeric_features = merged_data.select_dtypes(include=['int64', 'float64','uint8','uint16','float32']).columns\r\n",
    "\r\n",
    "categorical_features = merged_data.select_dtypes(include=['object']).columns\r\n",
    "\r\n",
    "class make_present_col_selector_class:\r\n",
    "    def __init__(self, selected_columns):\r\n",
    "        self.selected_columns = selected_columns\r\n",
    "\r\n",
    "    def __call__(self, df):\r\n",
    "        return [col for col in df.columns if col in self.selected_columns]\r\n",
    "\r\n",
    "preprocessor = ColumnTransformer(\r\n",
    "    transformers=[\r\n",
    "        ('numeric', numeric_transformer, make_present_col_selector_class(numeric_features)), \r\n",
    "        ('categorical', categorical_transformer, make_present_col_selector_class(categorical_features))\r\n",
    "    ])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating our RandomForestClassifier Pipeline with our preprocessor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "pipeline = Pipeline(steps=[\r\n",
    "    ('preprocessor', preprocessor), \r\n",
    "    ('regressor', RandomForestRegressor())\r\n",
    "])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Model using Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# Fit the pipeline with the data\r\n",
    "mlflow.autolog(log_input_examples=True, disable_for_unsupported_versions=True, silent=True)\r\n",
    "with mlflow.start_run() as run:\r\n",
    "    best_model = pipeline.fit(x_train, y_train)\r\n",
    "\r\n",
    "    train_score = best_model.score(x_train, y_train)\r\n",
    "    valid_score = best_model.score(x_valid, y_valid)\r\n",
    "    valid_metrics = calculate_metrics(y_valid, best_model.predict(x_valid))\r\n",
    "    test_score = best_model.score(x_test, y_test)\r\n",
    "    test_metrics = calculate_metrics(y_test, best_model.predict(x_test))\r\n",
    "\r\n",
    "    mlflow.log_metric(\"Valid Score\", valid_score)\r\n",
    "    mlflow.log_metrics(valid_metrics)\r\n",
    "    mlflow.log_metric(\"Test Score\", test_score)\r\n",
    "    mlflow.log_metrics(test_metrics)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parameter Tunning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Create dictionary with candidate learning algorithms and their hyperparameters\r\n",
    "grid_param = [{\r\n",
    "    \"regressor\": [RandomForestClassifier()],\r\n",
    "    \"regressor__n_estimators\": [10, 15],\r\n",
    "    \"regressor__max_depth\":[5, 8, 15],\r\n",
    "    \"regressor__min_samples_leaf\":[1, 2],\r\n",
    "    \"regressor__max_leaf_nodes\": [2, 5]\r\n",
    "}]\r\n",
    "     \r\n",
    "# create a gridsearch of the pipeline, the fit the best model\r\n",
    "grid_search_pipeline = GridSearchCV(\r\n",
    "    pipeline_rf, grid_param, cv=5, verbose=0, n_jobs=-1)  # Fit grid search\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit the grid search to the data\r\n",
    "with mlflow.start_run() as run:\r\n",
    "    best_model = grid_search_pipeline.fit(X_train, y_train)\r\n",
    "\r\n",
    "    train_score = best_model.score(x_train, y_train)\r\n",
    "    valid_score = best_model.score(x_valid, y_valid)\r\n",
    "    valid_metrics = calculate_metrics(y_valid, best_model.predict(x_valid))\r\n",
    "    test_score = best_model.score(x_test, y_test)\r\n",
    "    test_metrics = calculate_metrics(y_test, best_model.predict(x_test))\r\n",
    "\r\n",
    "    mlflow.log_metric(\"Valid Score\", valid_score)\r\n",
    "    mlflow.log_metrics(valid_metrics)\r\n",
    "    mlflow.log_metric(\"Test Score\", test_score)\r\n",
    "    mlflow.log_metrics(test_metrics)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediciton Interval"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\r\n",
    "# Set lower and upper quantile\r\n",
    "LOWER_ALPHA = 0.1\r\n",
    "UPPER_ALPHA = 0.9\r\n",
    "# Each model has to be separate\r\n",
    "lower_model = GradientBoostingRegressor(loss=\"quantile\",\r\n",
    "                                        alpha=LOWER_ALPHA)\r\n",
    "# The mid model will use the default loss\r\n",
    "mid_model = GradientBoostingRegressor(loss=\"ls\")\r\n",
    "upper_model = GradientBoostingRegressor(loss=\"quantile\",\r\n",
    "                                        alpha=UPPER_ALPHA)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit models\r\n",
    "lower_model.fit(X_train, y_train)\r\n",
    "mid_model.fit(X_train, y_train)\r\n",
    "upper_model.fit(X_train, y_train)\r\n",
    "# Record actual values on test set\r\n",
    "predictions = pd.DataFrame(y_test)\r\n",
    "# Predict\r\n",
    "predictions['lower'] = lower_model.predict(X_test)\r\n",
    "predictions['mid'] = mid_model.predict(X_test)\r\n",
    "predictions['upper'] = upper_model.predict(X_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "energy_data = go.Scatter(x=energy_series.index,\r\n",
    "                         y=energy_series.values)\r\n",
    "layout = go.Layout(title='Energy Plot', xaxis=dict(title='Date'),\r\n",
    "                   yaxis=dict(title='(kWh)'))\r\n",
    "fig = go.Figure(data=[energy_data], layout=layout)\r\n",
    "py.iplot(fig, sharing='public')\r\n",
    "\r\n",
    "\r\n",
    "# Get the steam data\r\n",
    "steam_series = df.loc[:, (\"Steam\", \"4\")]\r\n",
    "# Create the steam data object\r\n",
    "steam_data = go.Scatter(x=steam_series.index,\r\n",
    "                        y=steam_series.values,\r\n",
    "                        # Specify axis\r\n",
    "                        yaxis='y2')\r\n",
    "\r\n",
    "layout = go.Layout(height=600, width=800,\r\n",
    "                   title='Energy and Steam Plot',\r\n",
    "                   # Same x and first y\r\n",
    "                   xaxis=dict(title='Date'),\r\n",
    "                   yaxis=dict(title='Energy', color='red'),\r\n",
    "                   # Add a second yaxis to the right of the plot\r\n",
    "                   yaxis2=dict(title='Steam', color='blue',\r\n",
    "                               overlaying='y', side='right')\r\n",
    "                   )\r\n",
    "fig = go.Figure(data=[energy_data, steam_data], layout=layout)\r\n",
    "py.iplot(fig, sharing='public')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.4 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}